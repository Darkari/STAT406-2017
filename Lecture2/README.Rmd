---
title: "STAT406 - Lecture 2 notes"
author: "Matias Salibian-Barrera"
date: "`r format(Sys.Date())`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lecture slides

The lecture slides are [here](STAT406-17-lecture-2.pdf).

## Predictions using a linear model

Here we continue looking at the problem of estimating the
prediction power of different models. As in the previous lecture, we consider 
a **full** and a **reduced** model, and we assume that the
**reduced** model was not selected using the training data. 
We load the training set and fit both models:
```{r read}
x.tr <- read.table('../Lecture1/pollution-train.dat', header=TRUE, sep=',')
full <- lm(MORT ~ . , data=x.tr)
reduced <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x.tr)
```
Although the **full** model fits the data better than the
reduced one (see Lecture 1), its predictions on the test set are better:
```{r pred1}
x.te <- read.table('../Lecture1/pollution-test.dat', header=TRUE, sep=',')
pr.full <- predict(full, newdata=x.te)
pr.reduced <- predict(reduced, newdata=x.te)
with(x.te, mean( (MORT - pr.full)^2 ))
with(x.te, mean( (MORT - pr.reduced)^2 ))
```
In Lecture 1 we also saw that 
this is not just an artifact of the specific
training / test split of the data--the **reduced**
model generally produced better predictions, 
regardless of the specific training / test
split we used. 

A different procedure to estimate the prediction power
of a model or method is called *leave-one-out CV*. 
One advantage of using this method is that 
the model we fit can use a larger training set.
We discussed the procedure in class. Here
we apply it to estimate the mean squared
prediction error of the **full** and **reduced**
models.
```{r loocv}
x <- read.csv('../Lecture1/rutgers-lib-30861_CSV-1.csv')
n <- nrow(x)
pr.full <- pr.reduced <- rep(0, n)
for(i in 1:n) {
  full <- lm(MORT ~ . , data=x[-i, ])
  reduced <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x[-i, ])
  pr.full[i] <- predict(full, newdata = x[i, ])
  pr.reduced[i] <- predict(reduced, newdata = x[i, ])
}
mean( (x$MORT - pr.full)^2 )
mean( (x$MORT - pr.reduced)^2 )
```

Yet another method (computationally less costly) is
*K-fold CV*:
```{r kfold, fig.width=5, fig.height=5, echo=TRUE}
n <- nrow(x)
k <- 5
pr.full <- pr.reduced <- rep(0, n)
# This is bad, bad coding!
inds <- (1:n) %% k + 1 
# shuffle the rows of x, this is bad coding!
set.seed(123)
xs <- x[ sample(n, repl=FALSE), ]
# loop through the folds
for(j in 1:k) {
  x.tr <- xs[inds != j, ]
  x.te <- xs[inds == j, ]
  full <- lm(MORT ~ . , data=x.tr)
  reduced <- lm(MORT ~ POOR + HC + NOX + HOUS + NONW, data=x.tr)
  pr.full[ inds== j] <- predict(full, newdata=x.te)
  pr.reduced[ inds==j ] <- predict(reduced, newdata=x.te)
}
# compare predictions
mean( (xs$MORT - pr.full)^2 )
mean( (xs$MORT - pr.reduced)^2 )
```
